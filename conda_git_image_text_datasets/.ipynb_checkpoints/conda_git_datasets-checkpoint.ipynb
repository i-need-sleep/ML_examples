{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dental-baltimore",
   "metadata": {},
   "source": [
    "# Conda\n",
    "Why?  \n",
    "You might have different projects requiring differet sets of dependencies. You don't want to install them in the same environment or they might lead to dependency conflicts.  \n",
    "\n",
    "Ref:\n",
    "* [Official Guide](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html)\n",
    "* [Cheatsheet](https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf)\n",
    "\n",
    "TLDR:  \n",
    "Create a virtual environment\n",
    "```\n",
    "conda create -n my_env\n",
    "```\n",
    "Activate the env\n",
    "```\n",
    "conda activate my_env\n",
    "```\n",
    "Install packages\n",
    "```\n",
    "conda install my_package\n",
    "```\n",
    "or (if package not available in conda)\n",
    "```\n",
    "pip install my_package\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-weekly",
   "metadata": {},
   "source": [
    "# Git / Github\n",
    "Why?  \n",
    "You want to keep track of your source code as you create new versions (so you can revert if bad things happen). You want to pull/merge different versions so you can collaborate with teammates.  \n",
    "\n",
    "Ref:\n",
    "* [Official Guide](https://docs.github.com/en/get-started/quickstart/hello-world)\n",
    "* [Video Tutorial](https://www.youtube.com/watch?v=SWYqp7iY_Tc)\n",
    "* [Cheatsheet](https://training.github.com/downloads/github-git-cheat-sheet/)\n",
    "\n",
    "TLDR:  \n",
    "First-time setup for Git\n",
    "```\n",
    "git config --global user.name \"myname\"\n",
    "git config --global user.email \"my_email_on_github@example.com\"\n",
    "```\n",
    "Create a repo  \n",
    "Create a empty repo on github  \n",
    "cd to your project folder  \n",
    "copy and run all commands following \"create a new repository on the command line\"  \n",
    "add a .gitignore to avoid uploading big files  \n",
    "\n",
    "Upload to Github\n",
    "```\n",
    "git add .\n",
    "git commit -m \"my commit message\"\n",
    "git push -u origin main\n",
    "```\n",
    "\n",
    "Download from Github (first time)\n",
    "```\n",
    "git clone https://github.com/someone/somethingsomething.git\n",
    "```\n",
    "\n",
    "Download from Github (automatically merges)\n",
    "```\n",
    "git pull\n",
    "```\n",
    "\n",
    "Create/merge a branch\n",
    "```\n",
    "git branch branch-name\n",
    "git merge branch-name\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-pakistan",
   "metadata": {},
   "source": [
    "# Torch Dataset and Dataloader\n",
    "Ref:\n",
    "* [Official tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "* [Documentation](https://pytorch.org/docs/stable/data.html)    \n",
    "       \n",
    "* [Torchvision transforms](https://pytorch.org/vision/stable/transforms.html)\n",
    "      \n",
    "* [Huggingface tokenizers](https://huggingface.co/transformers/preprocessing.html)\n",
    "* [Tokenizing Chinese (a blog in Chinese)](https://zhuanlan.zhihu.com/p/371300063)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forbidden-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import glob # For listing things in a given folder\n",
    "import json # For handling json files\n",
    "\n",
    "# Image\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# Text\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "organized-copying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 300, 300])\n",
      "torch.Size([2, 3, 300, 300])\n",
      "torch.Size([1, 3, 300, 300])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\functional.py:127: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  img = torch.as_tensor(np.asarray(pic))\n"
     ]
    }
   ],
   "source": [
    "# Image example\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, img_root='./data/img/*'):\n",
    "        self.paths = glob.glob(img_root)\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.PILToTensor(),\n",
    "            transforms.CenterCrop(300),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3)\n",
    "            # Put more transforms here\n",
    "            ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def _show_img(self, img):\n",
    "        img = transforms.ToPILImage()(img)\n",
    "        img.show()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        image = Image.open(path)\n",
    "        \n",
    "        image = self.transforms(image)\n",
    "        \n",
    "#         self._show_img(image)\n",
    "#         uncomment me to show img\n",
    "\n",
    "        return image\n",
    "\n",
    "# collate function example:\n",
    "# Specify how data entries are combined into batches\n",
    "# What if we want to concatenate the image batch on the 0th axis\n",
    "def mr_collate(batch):\n",
    "#     [img_1, img_2, ...]\n",
    "#     print(batch)\n",
    "    return torch.cat(batch, axis=0)\n",
    "        \n",
    "def make_img_loader(batch_size, shuffle=True):\n",
    "    dataset = ImgDataset()\n",
    "    print(dataset[0].shape)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,) #collate_fn=mr_collate)\n",
    "    return loader\n",
    "        \n",
    "img_loader = make_img_loader(2)\n",
    "for idx, batch in enumerate(img_loader):\n",
    "    print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fluid-florist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '需', '要', '去', '[UNK]', '的', '[UNK]', '[UNK]']\n",
      "[2769, 7444, 6206, 1343, 100, 4638, 100, 100]\n",
      "['▁我', '需要', '去', 'Will', '的', 'Office', '▁Hour']\n",
      "[13129, 2745, 1677, 211673, 43, 94833, 133250]\n"
     ]
    }
   ],
   "source": [
    "# Text example\n",
    "# Tokenizers\n",
    "\n",
    "text_example = \"我需要去Will的Office Hour\"\n",
    "\n",
    "#char-level\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "tokens = tokenizer.tokenize(text_example)\n",
    "print(tokens)\n",
    "print(tokenizer.convert_tokens_to_ids(tokens))\n",
    "\n",
    "#SentencePiece\n",
    "#This MBART tokenizer is multilingual (works with multiple languages)\n",
    "tokenizer = transformers.models.mbart.tokenization_mbart.MBartTokenizer.from_pretrained(\"facebook/mbart-large-cc25\")\n",
    "tokens = tokenizer.tokenize(text_example)\n",
    "print(tokens)\n",
    "print(tokenizer.convert_tokens_to_ids(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "olive-shoulder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([16, 512])\n",
      "torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, tokenizer, path='./data/chinese_lyrics.json'):\n",
    "        \n",
    "        with open(path,'r') as f:\n",
    "            self.data = json.load(f)\n",
    "            # [{artist: '', title: '', lyrics:[[section],[section],...]}]\n",
    "        self.tokenizer = tokenizer\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #Flattern into a single string\n",
    "        lyrics = []\n",
    "        for lis in self.data[index][\"lyrics\"]:\n",
    "            lyrics += lis\n",
    "        lyrics = \", \".join(lyrics)\n",
    "        lyrics = self.tokenizer.bos_token + lyrics + tokenizer.eos_token\n",
    "        \n",
    "        ids = self.tokenizer(lyrics, truncation=True, padding='max_length', max_length=512)['input_ids']\n",
    "        return torch.tensor(ids)\n",
    "\n",
    "def make_text_loader(batch_size, shuffle=True):\n",
    "    tokenizer = transformers.models.mbart.tokenization_mbart.MBartTokenizer.from_pretrained(\"facebook/mbart-large-cc25\")\n",
    "    dataset = TextDataset(tokenizer)\n",
    "    print(dataset[0].shape)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle,) #collate_fn=mr_collate)\n",
    "    return loader\n",
    "\n",
    "text_loader = make_text_loader(16)\n",
    "for idx, batch in enumerate(text_loader):\n",
    "    print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
